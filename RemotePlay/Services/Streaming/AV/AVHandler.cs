using RemotePlay.Models.PlayStation;
using RemotePlay.Models.Streaming;
using RemotePlay.Services.Streaming.Quality;
using RemotePlay.Utils.Crypto;
using System.Collections.Concurrent;

namespace RemotePlay.Services.Streaming.AV
{
    /// <summary>
    /// AV å¤„ç†å™¨ V2 - å‚è€ƒ chiaki-ng çš„æ¶æ„é‡æ–°å®ç°
    /// ä½¿ç”¨ FrameProcessor å’Œ VideoReceiver åˆ†ç¦»å…³æ³¨ç‚¹
    /// </summary>
    public sealed class AVHandler
    {
        private readonly ILogger<AVHandler> _logger;
        private readonly string _hostType;
        private StreamCipher? _cipher;
        private IAVReceiver? _receiver;

        private readonly ConcurrentQueue<AVPacket> _queue = new();
        private ReorderQueue<AVPacket>? _videoReorderQueue;
        private CancellationTokenSource? _workerCts;
        private Task? _workerTask;
        private readonly CancellationToken _ct;

        private VideoReceiver? _videoReceiver;
        private AudioReceiver? _audioReceiver;

        private string? _detectedVideoCodec;
        private string? _detectedAudioCodec;
        private VideoProfile[]? _videoProfiles;
        
        // å›è°ƒ
        private Action<int, int>? _videoCorruptCallback;
        private Action<int, int>? _audioCorruptCallback;
        private Action<StreamHealthEvent>? _healthCallback;
        private AdaptiveStreamManager? _adaptiveStreamManager;
        private Action<VideoProfile, VideoProfile?>? _profileSwitchCallback;
        private Func<Task>? _requestKeyframeCallback;

        public AVHandler(
            ILogger<AVHandler> logger,
            string hostType,
            StreamCipher? cipher,
            IAVReceiver? receiver,
            CancellationToken ct)
        {
            _logger = logger;
            _hostType = hostType;
            _cipher = cipher;
            _receiver = receiver;
            _ct = ct;
            ResetVideoReorderQueue();
            
            // é‡ç½®è¶…æ—¶è®¡æ•°
            _consecutiveTimeouts = 0;
            _lastTimeoutTime = DateTime.MinValue;
        }

        #region Receiver / Cipher / Headers

        public void SetReceiver(IAVReceiver receiver)
        {
            if (receiver == null) throw new ArgumentNullException(nameof(receiver));

            var oldReceiver = _receiver;
            _receiver = receiver;

            if (oldReceiver != null)
                _logger.LogInformation("ğŸ”„ Switching receiver: {Old} -> {New}", oldReceiver.GetType().Name, receiver.GetType().Name);

            // åŒæ­¥ stream info å’Œ codec
            if (_videoProfiles != null && _videoProfiles.Length > 0)
            {
                try
                {
                    var currentProfile = _videoProfiles[0];
                    receiver.OnStreamInfo(currentProfile.HeaderWithPadding, Array.Empty<byte>());
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(ex, "Failed to send stream info to new receiver");
                }
            }

            if (_detectedVideoCodec != null) receiver.SetVideoCodec(_detectedVideoCodec);
            if (_detectedAudioCodec != null) receiver.SetAudioCodec(_detectedAudioCodec);
        }

        public void SetCipher(StreamCipher cipher)
        {
            _cipher = cipher;
            if (_receiver != null)
            {
                if (_workerTask == null || _workerTask.IsCompleted)
                    StartWorker();
            }
        }

        public void SetHeaders(byte[]? videoHeader, byte[]? audioHeader, ILoggerFactory loggerFactory)
        {
            // ä» AdaptiveStreamManager è·å– profiles
            VideoProfile[]? videoProfiles = null;
            if (_adaptiveStreamManager != null)
            {
                var profiles = _adaptiveStreamManager.GetAllProfiles();
                if (profiles.Count > 0)
                {
                    videoProfiles = profiles.ToArray();
                }
            }
            
            SetHeaders(videoHeader, audioHeader, videoProfiles, loggerFactory);
        }
        
        public void SetHeaders(byte[]? videoHeader, byte[]? audioHeader, VideoProfile[]? videoProfiles, ILoggerFactory loggerFactory)
        {
            if (_receiver == null)
            {
                _logger.LogWarning("âš ï¸ Cannot set headers: receiver is null");
                return;
            }

            ResetVideoReorderQueue();
            
            // é‡ç½®è¶…æ—¶è®¡æ•°
            _consecutiveTimeouts = 0;
            _lastTimeoutTime = DateTime.MinValue;

            // åˆå§‹åŒ– VideoReceiver
            _videoReceiver = new VideoReceiver(loggerFactory.CreateLogger<VideoReceiver>());
            if (videoProfiles != null && videoProfiles.Length > 0)
            {
                _videoProfiles = videoProfiles;
                _videoReceiver.SetStreamInfo(videoProfiles);
            }
            else if (videoHeader != null)
            {
                // å¦‚æœæ²¡æœ‰ profilesï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
                var defaultProfile = new VideoProfile(0, 1920, 1080, videoHeader);
                _videoProfiles = new[] { defaultProfile };
                _videoReceiver.SetStreamInfo(_videoProfiles);
            }

            // åˆå§‹åŒ– AudioReceiver
            _audioReceiver = new AudioReceiver(loggerFactory.CreateLogger<AudioReceiver>());
            if (audioHeader != null)
            {
                _audioReceiver.SetHeader(audioHeader);
            }

            if (_cipher != null)
            {
                if (_workerTask == null || _workerTask.IsCompleted)
                    StartWorker();
            }
            else
            {
                _logger.LogWarning("âš ï¸ SetHeaders called but cipher is null");
            }
        }

        #endregion

        #region Packet Handling

        public void AddPacket(byte[] msg)
        {
            try
            {
                if (!AVPacket.TryParse(msg, _hostType, out var packet))
                {
                    _logger.LogWarning("âš ï¸ Failed to parse AV packet, len={Len}", msg.Length);
                    return;
                }

                if (packet.Type == HeaderType.VIDEO)
                {
                    if (_videoReorderQueue == null)
                    {
                        _logger.LogWarning("âš ï¸ Video reorder queue is null, cannot process video packet");
                        return;
                    }

                    _videoReorderQueue?.Push(packet);
                    _videoReorderQueue?.Flush(false);
                }
                else
                {
                    HandleOrderedPacket(packet);
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ Exception in AddPacket, len={Len}", msg.Length);
            }
        }

        private void ProcessSinglePacket(AVPacket packet)
        {
            // æ£€æµ‹å¹¶å¤„ç† adaptive_stream_index åˆ‡æ¢
            if (packet.Type == HeaderType.VIDEO && _adaptiveStreamManager != null)
            {
                var (switched, newProfile, needUpdateHeader) = _adaptiveStreamManager.CheckAndHandleSwitch(packet, _profileSwitchCallback);
                
                if (switched && needUpdateHeader && newProfile != null)
                {
                    // æ›´æ–° VideoReceiver çš„ profiles
                    if (_videoReceiver != null && _videoProfiles != null)
                    {
                        _videoReceiver.SetStreamInfo(_videoProfiles);
                    }
                }
            }

            byte[] decrypted = DecryptPacket(packet);
            if (packet.Type == HeaderType.VIDEO)
            {
                if (_videoReceiver == null)
                {
                    _logger.LogError("âŒ VideoReceiver null, frame={Frame}", packet.FrameIndex);
                    return;
                }

                _videoReceiver.ProcessPacket(packet, decrypted, (frame, recovered, success) =>
                {
                    if (_receiver != null && success)
                    {
                        var packetData = new byte[1 + frame.Length];
                        packetData[0] = (byte)HeaderType.VIDEO;
                        Array.Copy(frame, 0, packetData, 1, frame.Length);
                        try
                        {
                            _receiver.OnVideoPacket(packetData);
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "âŒ OnVideoPacket å¼‚å¸¸");
                        }
                    }
                });
            }
            else
            {
                if (_audioReceiver == null)
                {
                    _logger.LogWarning("âš ï¸ AudioReceiver is null, cannot process audio packet");
                    return;
                }

                _audioReceiver.ProcessPacket(packet, decrypted, (frame) =>
                {
                    if (_receiver != null)
                    {
                        var packetData = new byte[1 + frame.Length];
                        packetData[0] = (byte)HeaderType.AUDIO;
                        Array.Copy(frame, 0, packetData, 1, frame.Length);
                        try
                        {
                            _receiver.OnAudioPacket(packetData);
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "âŒ OnAudioPacket å¼‚å¸¸");
                        }
                    }
                });
            }
        }

        private byte[] DecryptPacket(AVPacket packet)
        {
            var data = packet.Data;
            if (_cipher != null && data.Length > 0 && packet.KeyPos > 0)
            {
                try { data = _cipher.Decrypt(data, (int)packet.KeyPos); }
                catch (Exception ex) { _logger.LogError(ex, "âŒ Decrypt failed frame={Frame}", packet.FrameIndex); }
            }
            return data;
        }

        #endregion

        #region Callbacks

        public void SetCorruptFrameCallbacks(Action<int, int>? videoCallback, Action<int, int>? audioCallback = null)
        {
            _videoCorruptCallback = videoCallback;
            _audioCorruptCallback = audioCallback;
        }

        public void SetStreamHealthCallback(Action<StreamHealthEvent>? healthCallback)
        {
            _healthCallback = healthCallback;
        }

        public void SetAdaptiveStreamManager(AdaptiveStreamManager? manager, Action<VideoProfile, VideoProfile?>? onProfileSwitch = null)
        {
            _adaptiveStreamManager = manager;
            _profileSwitchCallback = onProfileSwitch;
        }

        public void SetRequestKeyframeCallback(Func<Task>? callback)
        {
            _requestKeyframeCallback = callback;
        }

        #endregion

        #region Reorder Queue

        private void ResetVideoReorderQueue()
        {
            _videoReorderQueue = new ReorderQueue<AVPacket>(
                _logger,
                pkt => (uint)pkt.Index,
                HandleOrderedPacket,
                dropCallback: (droppedPacket) =>
                {
                    _logger.LogWarning("âš ï¸ Video packet dropped in reorder queue: seq={Seq}, frame={Frame}",
                        droppedPacket.Index, droppedPacket.FrameIndex);
                },
                sizeStart: 64,
                sizeMin: 32,
                sizeMax: 256,
                timeoutMs: 200,
                dropStrategy: ReorderQueueDropStrategy.Begin,
                timeoutCallback: OnReorderQueueTimeout);
        }

        // è¶…æ—¶æ¢å¤æœºåˆ¶ï¼šè·Ÿè¸ªè¿ç»­è¶…æ—¶æ¬¡æ•°ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶è¯·æ±‚å…³é”®å¸§
        private int _consecutiveTimeouts = 0;
        private DateTime _lastTimeoutTime = DateTime.MinValue;
        private const int MAX_CONSECUTIVE_TIMEOUTS = 10; // è¿ç»­è¶…æ—¶10æ¬¡åè¯·æ±‚å…³é”®å¸§
        private const int TIMEOUT_WINDOW_MS = 2000; // 2ç§’å†…çš„è¶…æ—¶æ‰ç®—è¿ç»­

        private void OnReorderQueueTimeout()
        {
            var now = DateTime.UtcNow;
            
            // æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´çª—å£å†…
            if (_lastTimeoutTime != DateTime.MinValue && 
                (now - _lastTimeoutTime).TotalMilliseconds > TIMEOUT_WINDOW_MS)
            {
                // è¶…è¿‡æ—¶é—´çª—å£ï¼Œé‡ç½®è®¡æ•°
                _consecutiveTimeouts = 0;
            }

            _consecutiveTimeouts++;
            _lastTimeoutTime = now;

            // å¦‚æœè¿ç»­è¶…æ—¶æ¬¡æ•°è¶…è¿‡é˜ˆå€¼ï¼Œè¯·æ±‚å…³é”®å¸§æ¢å¤
            if (_consecutiveTimeouts >= MAX_CONSECUTIVE_TIMEOUTS)
            {
                _logger.LogWarning("âš ï¸ è¿ç»­è¶…æ—¶ {Count} æ¬¡ï¼Œè¯·æ±‚å…³é”®å¸§æ¢å¤è§†é¢‘æµ", _consecutiveTimeouts);
                
                // é‡ç½®è®¡æ•°ï¼Œé¿å…é‡å¤è¯·æ±‚
                _consecutiveTimeouts = 0;
                _lastTimeoutTime = DateTime.MinValue;

                // å¼‚æ­¥è¯·æ±‚å…³é”®å¸§ï¼ˆä¸é˜»å¡ï¼‰
                if (_requestKeyframeCallback != null)
                {
                    _ = Task.Run(async () =>
                    {
                        try
                        {
                            await _requestKeyframeCallback();
                            _logger.LogInformation("âœ… å·²è¯·æ±‚å…³é”®å¸§æ¢å¤è§†é¢‘æµ");
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "âŒ è¯·æ±‚å…³é”®å¸§å¤±è´¥");
                        }
                    });
                }
                else
                {
                    _logger.LogWarning("âš ï¸ æœªè®¾ç½® RequestKeyframeCallbackï¼Œæ— æ³•è¯·æ±‚å…³é”®å¸§");
                }
            }
        }

        private void HandleOrderedPacket(AVPacket packet)
        {
            bool isVideo = packet.Type == HeaderType.VIDEO;

            if (packet.Type == HeaderType.VIDEO && _detectedVideoCodec == null)
                DetectVideoCodec(packet);
            if (packet.Type == HeaderType.AUDIO && _detectedAudioCodec == null)
                DetectAudioCodec(packet);

            if (_receiver == null)
                return;

            // éŸ³é¢‘åŒ…ä¼˜å…ˆç›´æ¥å¤„ç†
            if (!isVideo)
            {
                try
                {
                    ProcessSinglePacket(packet);
                    return;
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(ex, "âš ï¸ Audio direct processing failed, enqueue instead");
                }
            }

            // å¦‚æœé˜Ÿåˆ—è¾ƒå°ï¼Œä¼˜å…ˆç›´æ¥å¤„ç†
            if (_queue.Count < 10)
            {
                try
                {
                    ProcessSinglePacket(packet);
                    return;
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(ex, "âš ï¸ Direct processing failed, enqueue instead");
                }
            }

            _queue.Enqueue(packet);

            if (_queue.Count > 100 && (_workerTask == null || _workerTask.IsCompleted) && _cipher != null)
            {
                _logger.LogError("âŒ Queue has {Size} packets but worker not running! Starting...", _queue.Count);
                StartWorker();
            }
        }

        #endregion

        #region Codec Detection

        private void DetectAudioCodec(AVPacket packet)
        {
            string codec = packet.Codec switch
            {
                0x01 or 0x02 => "opus",
                0x03 or 0x04 => "aac",
                _ => "opus"
            };
            if (codec == "opus" && packet.Codec != 0x01 && packet.Codec != 0x02)
                _logger.LogWarning("âš ï¸ Unknown audio codec 0x{Codec:X2}, defaulting to opus", packet.Codec);

            _detectedAudioCodec = codec;
            _receiver?.SetAudioCodec(codec);
        }

        private void DetectVideoCodec(AVPacket packet)
        {
            // ä» profile header æ£€æµ‹ codec
            string? codec = null;
            if (_videoProfiles != null && _videoProfiles.Length > 0)
            {
                codec = DetectCodecFromHeader(_videoProfiles[0].Header);
            }

            if (codec != null)
            {
                _detectedVideoCodec = codec;
                _receiver?.SetVideoCodec(codec);
                _logger.LogInformation("ğŸ“¹ Detected video codec: {Codec}", codec);
                return;
            }

            _detectedVideoCodec = packet.Codec switch
            {
                0x06 => "h264",
                0x36 or 0x37 => "hevc",
                _ => "h264"
            };
            _receiver?.SetVideoCodec(_detectedVideoCodec);
        }

        private string? DetectCodecFromHeader(byte[] header)
        {
            int len = Math.Max(header.Length - 64, 0);
            for (int i = 0; i < len - 4; i++)
            {
                if (header[i] == 0x00 && header[i + 1] == 0x00)
                {
                    int offset = header[i + 2] == 0x01 ? 3 : (header[i + 2] == 0x00 && header[i + 3] == 0x01 ? 4 : 0);
                    if (offset == 0) continue;
                    byte nal = header[i + offset];
                    if ((nal & 0x7E) == 0x40 || (nal & 0x7E) == 0x42 || (nal & 0x7E) == 0x44) return "hevc";
                    if ((nal & 0x1F) is 5 or 7 or 8) return "h264";
                }
            }
            return null;
        }

        #endregion

        #region Worker

        public void StartWorker()
        {
            if (_workerTask != null && !_workerTask.IsCompleted) return;

            _workerCts?.Cancel();
            _workerCts = new CancellationTokenSource();
            var token = _workerCts.Token;

            _workerTask = Task.Run(() =>
            {
                _logger.LogInformation("âœ… AVHandler2 worker started");
                int processedCount = 0;

                while (!token.IsCancellationRequested && !_ct.IsCancellationRequested)
                {
                    int batch = 50;
                    int processedInBatch = 0;

                    for (int i = 0; i < batch; i++)
                    {
                        if (!_queue.TryDequeue(out var pkt)) break;
                        try
                        {
                            ProcessSinglePacket(pkt);
                            processedCount++;
                            processedInBatch++;
                        }
                        catch (Exception ex)
                        {
                            _logger.LogError(ex, "âŒ Error processing AV packet frame={Frame}", pkt.FrameIndex);
                        }
                    }

                    if (_queue.IsEmpty)
                    {
                        Thread.Sleep(1);
                    }
                    else
                    {
                        Thread.Yield();
                    }
                }

                _queue.Clear();
                _logger.LogDebug("AVHandler2 worker stopped, total processed={Count}", processedCount);
            }, token);
        }

        #endregion

        #region Stop & Stats

        public void Stop()
        {
            _logger.LogDebug("ğŸ›‘ AVHandler2.Stop() called");

            _workerCts?.Cancel();
            _queue.Clear();
            ResetVideoReorderQueue();
            
            // é‡ç½®è¶…æ—¶è®¡æ•°
            _consecutiveTimeouts = 0;
            _lastTimeoutTime = DateTime.MinValue;

            if (_workerTask != null && !_workerTask.IsCompleted)
            {
                try
                {
                    var timeoutTask = Task.Delay(500);
                    var completedTask = Task.WhenAny(_workerTask, timeoutTask).GetAwaiter().GetResult();
                    if (completedTask == timeoutTask)
                    {
                        _logger.LogWarning("âš ï¸ AVHandler2 worker é€€å‡ºè¶…æ—¶ï¼ˆ500msï¼‰ï¼Œå¼ºåˆ¶ç»§ç»­");
                    }
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(ex, "âš ï¸ ç­‰å¾… AVHandler2 worker é€€å‡ºæ—¶å‘ç”Ÿå¼‚å¸¸");
                }
            }
        }

        public StreamPipelineStats GetAndResetStats()
        {
            // TODO: å®ç°ç»Ÿè®¡ä¿¡æ¯
            return new StreamPipelineStats
            {
                VideoReceived = 0,
                VideoLost = 0,
                VideoTimeoutDropped = 0,
                AudioReceived = 0,
                AudioLost = 0,
                AudioTimeoutDropped = 0,
                PendingPackets = _queue.Count,
                FecAttempts = 0,
                FecSuccess = 0,
                FecFailures = 0,
                FecSuccessRate = 0.0
            };
        }

        public StreamHealthSnapshot GetHealthSnapshot(bool resetDeltas = false, bool resetStreamStats = false)
        {
            // TODO: å®ç°å¥åº·å¿«ç…§ï¼ˆç®€åŒ–ç‰ˆï¼‰
            return new StreamHealthSnapshot
            {
                Timestamp = DateTime.UtcNow,
                LastStatus = FrameProcessStatus.Success,
                Message = null,
                ConsecutiveFailures = 0,
                TotalRecoveredFrames = 0,
                TotalFrozenFrames = 0,
                TotalDroppedFrames = 0,
                DeltaRecoveredFrames = 0,
                DeltaFrozenFrames = 0,
                DeltaDroppedFrames = 0,
                RecentWindowSeconds = 10,
                RecentSuccessFrames = 0,
                RecentRecoveredFrames = 0,
                RecentFrozenFrames = 0,
                RecentDroppedFrames = 0,
                RecentFps = 0,
                AverageFrameIntervalMs = 0,
                LastFrameTimestampUtc = DateTime.UtcNow,
                TotalFrames = 0,
                TotalBytes = 0,
                MeasuredBitrateMbps = 0,
                FramesLost = 0,
                FrameIndexPrev = -1
            };
        }

        #endregion
    }
}

