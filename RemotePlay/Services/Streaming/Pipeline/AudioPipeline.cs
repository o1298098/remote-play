using System;
using System.Threading;
using System.Threading.Channels;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using RemotePlay.Models.Streaming;
using RemotePlay.Services.Streaming.AV;
using RemotePlay.Services.Streaming.Receiver;
using RemotePlay.Services.Streaming.Protocol;
using RemotePlay.Utils.Crypto;

namespace RemotePlay.Services.Streaming.Pipeline
{
    /// <summary>
    /// Audio Pipeline - è´Ÿè´£éŸ³é¢‘åŒ…çš„å¤„ç†
    /// è®¾è®¡ç›®æ ‡ï¼š
    /// 1. ç‹¬ç«‹çº¿ç¨‹å¤„ç†ï¼ˆä¸é˜»å¡ Ingest å’Œ Videoï¼‰
    /// 2. ä½å»¶è¿Ÿï¼ˆéŸ³é¢‘ä¸ç»è¿‡ ReorderQueueï¼‰
    /// 3. å¿«é€Ÿé€šé“ï¼ˆä¼˜å…ˆçº§é«˜äºè§†é¢‘ï¼‰
    /// </summary>
    public sealed class AudioPipeline : IDisposable
    {
        private readonly ILogger<AudioPipeline> _logger;
        private readonly ChannelReader<AVPacket> _inputReader;
        private readonly Channel<ProcessedFrame> _outputChannel;
        private readonly AudioReceiver? _audioReceiver;
        private readonly CancellationTokenSource _cts = new();
        private readonly Task _workerTask;

        // é…ç½®
        private string? _detectedCodec;
        private Action<int>? _frameLossCallback;
        private StreamCipher? _cipher;  // âš ï¸ è§£å¯†å¯†é’¥ï¼ˆä¸æ—§çš„ AVHandler ä¸€è‡´ï¼‰

        // ç»Ÿè®¡
        private long _totalReceived;
        private long _totalProcessed;
        private long _totalDropped;
        private long _framesComplete;

        public AudioPipeline(
            ILogger<AudioPipeline> logger,
            ChannelReader<AVPacket> inputReader,
            ILoggerFactory loggerFactory,
            int outputCapacity = 512)
        {
            _logger = logger;
            _inputReader = inputReader;

            _outputChannel = Channel.CreateBounded<ProcessedFrame>(new BoundedChannelOptions(outputCapacity)
            {
                FullMode = BoundedChannelFullMode.DropOldest,
                SingleReader = false,
                SingleWriter = true
            });

            // åˆå§‹åŒ– AudioReceiver
            _audioReceiver = new AudioReceiver(loggerFactory.CreateLogger<AudioReceiver>());

            _workerTask = Task.Run(WorkerLoop, _cts.Token);
        }

        #region Public API

        /// <summary>
        /// è·å–è¾“å‡º Channel
        /// </summary>
        public ChannelReader<ProcessedFrame> OutputReader => _outputChannel.Reader;

        /// <summary>
        /// è®¾ç½®éŸ³é¢‘ Header
        /// </summary>
        public void SetHeader(byte[]? audioHeader)
        {
            _audioReceiver?.SetHeader(audioHeader);
        }

        /// <summary>
        /// è®¾ç½®éŸ³é¢‘ç¼–è§£ç å™¨
        /// </summary>
        public void SetAudioCodec(string codec)
        {
            _detectedCodec = codec;
        }

        /// <summary>
        /// è®¾ç½®å¸§ä¸¢å¤±å›è°ƒ
        /// </summary>
        public void SetFrameLossCallback(Action<int>? callback)
        {
            _frameLossCallback = callback;
            _audioReceiver?.SetFrameLossCallback(callback);
        }

        /// <summary>
        /// è®¾ç½®è§£å¯†å¯†é’¥ï¼ˆä¸æ—§çš„ AVHandler ä¸€è‡´ï¼‰
        /// </summary>
        public void SetCipher(StreamCipher? cipher)
        {
            _cipher = cipher;
        }

        /// <summary>
        /// è·å–ç»Ÿè®¡ä¿¡æ¯
        /// </summary>
        public AudioStats GetStats()
        {
            return new AudioStats
            {
                TotalReceived = Interlocked.Read(ref _totalReceived),
                TotalProcessed = Interlocked.Read(ref _totalProcessed),
                TotalDropped = Interlocked.Read(ref _totalDropped),
                FramesComplete = Interlocked.Read(ref _framesComplete),
                OutputQueueSize = _outputChannel.Reader.Count
            };
        }

        #endregion

        #region Worker Loop

        private async Task WorkerLoop()
        {
            _logger.LogInformation("âœ… AudioPipeline worker started");

            try
            {
                await foreach (var packet in _inputReader.ReadAllAsync(_cts.Token))
                {
                    try
                    {
                        Interlocked.Increment(ref _totalReceived);

                        // è‡ªåŠ¨æ£€æµ‹ç¼–è§£ç å™¨
                        if (_detectedCodec == null)
                        {
                            DetectAudioCodec(packet);
                        }

                        // ç›´æ¥å¤„ç†ï¼ˆéŸ³é¢‘ä¸éœ€è¦é‡æ’åºï¼‰
                        HandlePacket(packet);
                    }
                    catch (Exception ex)
                    {
                        _logger.LogError(ex, "âŒ AudioPipeline processing error, frame={Frame}", packet.FrameIndex);
                    }
                }
            }
            catch (OperationCanceledException)
            {
                // æ­£å¸¸é€€å‡º
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ AudioPipeline worker exception");
            }
            finally
            {
                _logger.LogInformation("âœ… AudioPipeline worker exited");
            }
        }

        #endregion

        #region Packet Processing

        private void HandlePacket(AVPacket packet)
        {
            try
            {
                if (_audioReceiver == null)
                {
                    _logger.LogWarning("âš ï¸ AudioReceiver is null");
                    return;
                }

                // âš ï¸ å…³é”®ä¿®å¤ï¼šè§£å¯†å·²åœ¨ IngestPipeline ä¸­å®Œæˆï¼ˆä¸²è¡Œå¤„ç†ï¼Œä¿è¯ keyPos é¡ºåºï¼‰
                // packet.Data å·²ç»æ˜¯è§£å¯†åçš„æ•°æ®
                _audioReceiver.ProcessPacket(packet, packet.Data, (frame) =>
                {
                    Interlocked.Increment(ref _totalProcessed);
                    Interlocked.Increment(ref _framesComplete);

                    // åˆ›å»ºå¤„ç†åçš„å¸§
                    var processedFrame = new ProcessedFrame
                    {
                        Type = FrameType.Audio,
                        FrameIndex = packet.FrameIndex,
                        Data = frame,
                        Recovered = false,
                        Timestamp = DateTime.UtcNow,
                        IsKeyFrame = false
                    };

                    // æ¨é€åˆ°è¾“å‡ºé˜Ÿåˆ—ï¼ˆéé˜»å¡ï¼‰
                    if (!_outputChannel.Writer.TryWrite(processedFrame))
                    {
                        Interlocked.Increment(ref _totalDropped);
                        _logger.LogWarning("âš ï¸ AudioPipeline output queue full, dropping frame={Frame}",
                            packet.FrameIndex);
                    }
                });
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ HandlePacket error, frame={Frame}", packet.FrameIndex);
            }
        }

        #endregion

        #region Decryption

        /// <summary>
        /// è§£å¯†åŒ…æ•°æ®ï¼ˆä¸æ—§çš„ AVHandler å®Œå…¨ä¸€è‡´ï¼‰
        /// </summary>
        private byte[] DecryptPacket(AVPacket packet)
        {
            var data = packet.Data;
            if (_cipher != null && data.Length > 0 && packet.KeyPos > 0)
            {
                try 
                { 
                    data = _cipher.Decrypt(data, (int)packet.KeyPos); 
                }
                catch (Exception ex) 
                { 
                    _logger.LogError(ex, "âŒ Decrypt failed frame={Frame}", packet.FrameIndex); 
                }
            }
            return data;
        }

        #endregion

        #region Codec Detection

        private void DetectAudioCodec(AVPacket packet)
        {
            string codec = packet.Codec switch
            {
                0x01 or 0x02 => "opus",
                0x03 or 0x04 => "aac",
                _ => "opus"
            };

            if (codec == "opus" && packet.Codec != 0x01 && packet.Codec != 0x02)
            {
                _logger.LogWarning("âš ï¸ Unknown audio codec 0x{Codec:X2}, defaulting to opus", packet.Codec);
            }

            _detectedCodec = codec;
            _logger.LogInformation("ğŸ”Š Detected audio codec: {Codec}", codec);
        }

        #endregion

        #region Dispose

        public void Dispose()
        {
            _cts.Cancel();

            try
            {
                _workerTask.Wait(TimeSpan.FromMilliseconds(500));
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "âš ï¸ AudioPipeline dispose error");
            }

            _outputChannel.Writer.Complete();
            _cts.Dispose();
        }

        #endregion
    }

    /// <summary>
    /// Audio Pipeline ç»Ÿè®¡ä¿¡æ¯
    /// </summary>
    public struct AudioStats
    {
        public long TotalReceived { get; set; }
        public long TotalProcessed { get; set; }
        public long TotalDropped { get; set; }
        public long FramesComplete { get; set; }
        public int OutputQueueSize { get; set; }
    }
}

