using System;
using System.Threading;
using System.Threading.Channels;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using RemotePlay.Models.PlayStation;
using RemotePlay.Models.Streaming;
using RemotePlay.Services.Streaming.AV;
using RemotePlay.Services.Streaming.Quality;
using RemotePlay.Services.Streaming.Receiver;
using RemotePlay.Services.Streaming.Protocol;
using RemotePlay.Utils.Crypto;

namespace RemotePlay.Services.Streaming.Pipeline
{
    /// <summary>
    /// AV Pipeline Coordinator - åè°ƒæ‰€æœ‰ Pipeline ç»„ä»¶
    /// 
    /// æ¶æ„ï¼š
    /// Network â†’ IngestPipeline (è§£æ+è§£å¯†)
    ///             â†“
    ///        PacketRouter (åˆ†å‘)
    ///         â†™        â†˜
    ///   VideoPipeline  AudioPipeline (æ‹¼å¸§)
    ///         â†“            â†“
    ///        OutputPipeline (å¼‚æ­¥å‘é€åˆ° WebRTC)
    /// 
    /// ä¼˜åŠ¿ï¼š
    /// 1. å®Œå…¨å¼‚æ­¥ï¼Œæ— é˜»å¡
    /// 2. å„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºè°ƒè¯•
    /// 3. èƒŒå‹ä¿æŠ¤
    /// 4. æ€§èƒ½ç›‘æ§
    /// </summary>
    public sealed class AVPipelineCoordinator : IDisposable
    {
        private readonly ILogger<AVPipelineCoordinator> _logger;
        private readonly ILoggerFactory _loggerFactory;
        private readonly string _hostType;
        private readonly CancellationToken _ct;

        // Pipeline ç»„ä»¶
        private readonly IngestPipeline _ingestPipeline;
        private readonly VideoPipeline _videoPipeline;
        private readonly AudioPipeline _audioPipeline;
        private readonly OutputPipeline _outputPipeline;

        // è·¯ç”±ä»»åŠ¡
        private readonly CancellationTokenSource _routerCts = new();
        private readonly Task _routerTask;
        private readonly Task _packetRouterTask;

        // é…ç½®
        private IAVReceiver? _receiver;

        public AVPipelineCoordinator(
            ILogger<AVPipelineCoordinator> logger,
            ILoggerFactory loggerFactory,
            string hostType,
            IAVReceiver receiver,
            CancellationToken ct)
        {
            _logger = logger;
            _loggerFactory = loggerFactory;
            _hostType = hostType;
            _receiver = receiver;
            _ct = ct;

            // åˆ›å»º Pipeline ç»„ä»¶
            _ingestPipeline = new IngestPipeline(
                loggerFactory.CreateLogger<IngestPipeline>(),
                hostType,
                inputCapacity: 2048,
                outputCapacity: 2048);

            var ingestOutput = _ingestPipeline.OutputReader;

            _videoPipeline = new VideoPipeline(
                loggerFactory.CreateLogger<VideoPipeline>(),
                CreateVideoPipelineInput(ingestOutput),
                loggerFactory,
                outputCapacity: 512,
                enableReorder: true,        
                reorderWindowSize: 256,
                reorderTimeoutMs: 300);    

            _audioPipeline = new AudioPipeline(
                loggerFactory.CreateLogger<AudioPipeline>(),
                CreateAudioPipelineInput(ingestOutput),
                loggerFactory,
                outputCapacity: 512);

            _outputPipeline = new OutputPipeline(
                loggerFactory.CreateLogger<OutputPipeline>(),
                receiver,
                videoQueueCapacity: 256,
                audioQueueCapacity: 512);

            // å¯åŠ¨ç»Ÿä¸€çš„åŒ…è·¯ç”±ä»»åŠ¡
            _packetRouterTask = Task.Run(RoutePacketsFromIngest, _routerCts.Token);

            // å¯åŠ¨å¸§è·¯ç”±ä»»åŠ¡
            _routerTask = Task.Run(async () =>
            {
                await Task.WhenAll(
                    RouteVideoFrames(),
                    RouteAudioFrames()
                );
            }, _routerCts.Token);

            _logger.LogInformation("âœ… AVPipelineCoordinator initialized");
        }

    #region Pipeline Input Channels

    // ä½¿ç”¨ç‹¬ç«‹çš„ Channelï¼Œé¿å…å¤šè¯»å–è€…ç«äº‰
    private readonly Channel<AVPacket> _videoInputChannel = Channel.CreateBounded<AVPacket>(new BoundedChannelOptions(2048)
    {
        FullMode = BoundedChannelFullMode.DropOldest,
        SingleReader = true,
        SingleWriter = true
    });

    private readonly Channel<AVPacket> _audioInputChannel = Channel.CreateBounded<AVPacket>(new BoundedChannelOptions(2048)
    {
        FullMode = BoundedChannelFullMode.DropOldest,
        SingleReader = true,
        SingleWriter = true
    });

    private ChannelReader<AVPacket> CreateVideoPipelineInput(ChannelReader<AVPacket> source)
    {
        return _videoInputChannel.Reader;
    }

    private ChannelReader<AVPacket> CreateAudioPipelineInput(ChannelReader<AVPacket> source)
    {
        return _audioInputChannel.Reader;
    }

    #endregion

    #region Routing Tasks

    /// <summary>
    /// ç»Ÿä¸€çš„åŒ…è·¯ç”±ä»»åŠ¡ï¼šä» Ingest è¯»å–åŒ…å¹¶æ ¹æ®ç±»å‹åˆ†å‘åˆ° Video/Audio Pipeline
    /// ç»Ÿä¸€çš„åŒ…è·¯ç”±ä»»åŠ¡ï¼šä» Ingest è¯»å–åŒ…å¹¶æ ¹æ®ç±»å‹åˆ†å‘åˆ° Video/Audio Pipeline
    /// </summary>
    private async Task RoutePacketsFromIngest()
    {
        long totalRouted = 0;
        long videoRouted = 0;
        long audioRouted = 0;
        long unknownType = 0;

        try
        {
            await foreach (var packet in _ingestPipeline.OutputReader.ReadAllAsync(_routerCts.Token))
            {
                totalRouted++;

                // æ ¹æ®ç±»å‹åˆ†å‘åˆ°å¯¹åº”çš„ Pipeline
                if (packet.Type == HeaderType.VIDEO)
                {
                    videoRouted++;
                    await _videoInputChannel.Writer.WriteAsync(packet, _routerCts.Token);
                }
                else if (packet.Type == HeaderType.AUDIO)
                {
                    audioRouted++;
                    await _audioInputChannel.Writer.WriteAsync(packet, _routerCts.Token);
                }
                else
                {
                    unknownType++;
                    _logger.LogWarning("âš ï¸ Unknown packet type: {Type}", packet.Type);
                }
            }
        }
        catch (OperationCanceledException) { }
        catch (Exception ex)
        {
            _logger.LogError(ex, "âŒ RoutePacketsFromIngest exception");
        }
        finally
        {
            _videoInputChannel.Writer.Complete();
            _audioInputChannel.Writer.Complete();
            _logger.LogInformation(
                "ğŸ›‘ PacketRouter stopped. Total={Total}, Video={Video}, Audio={Audio}, Unknown={Unknown}",
                totalRouted, videoRouted, audioRouted, unknownType
            );
        }
    }

        private async Task RouteVideoFrames()
        {
            try
            {
                long frameCount = 0;
                await foreach (var frame in _videoPipeline.OutputReader.ReadAllAsync(_routerCts.Token))
                {
                    frameCount++;
                    bool pushed = _outputPipeline.TryPushVideoFrame(frame);
                    if (!pushed)
                    {
                        _logger.LogWarning("âš ï¸ RouteVideoFrames: Failed to push frame={Frame} to OutputPipeline", frame.FrameIndex);
                    }
                    else if (frameCount % 100 == 0)
                    {
                        _logger.LogDebug("ğŸ” RouteVideoFrames: Routed {Count} frames to OutputPipeline", frameCount);
                    }
                }
                _logger.LogDebug("ğŸ” RouteVideoFrames: Total routed {Count} frames", frameCount);
            }
            catch (OperationCanceledException) { }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ RouteVideoFrames exception");
            }
        }

        private async Task RouteAudioFrames()
        {
            try
            {
                await foreach (var frame in _audioPipeline.OutputReader.ReadAllAsync(_routerCts.Token))
                {
                    _outputPipeline.TryPushAudioFrame(frame);
                }
            }
            catch (OperationCanceledException) { }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ RouteAudioFrames exception");
            }
        }

        #endregion

        #region Public API

        /// <summary>
        /// æ·»åŠ ç½‘ç»œåŒ…ï¼ˆå…¥å£ç‚¹ï¼‰
        /// </summary>
        public void AddPacket(byte[] msg)
        {
            _ingestPipeline.TryPushRawData(msg);
        }

        /// <summary>
        /// è®¾ç½®æ¥æ”¶å™¨
        /// è®¾ç½®æ¥æ”¶å™¨ï¼ŒåŒæ—¶æ›´æ–° OutputPipeline çš„ receiver
        /// </summary>
        public void SetReceiver(IAVReceiver receiver)
        {
            _receiver = receiver;
            _outputPipeline.SetReceiver(receiver);
            _logger.LogInformation("âœ… AVPipelineCoordinator: Receiver switched to {Receiver}", receiver?.GetType().Name ?? "null");
        }

        /// <summary>
        /// è®¾ç½®è§£å¯†å¯†é’¥
        /// è®¾ç½®è§£å¯†å¯†é’¥
        /// è§£å¯†åœ¨ IngestPipeline ä¸­ä¸²è¡Œè¿›è¡Œï¼Œé¿å…å¹¶è¡Œè§£å¯†å¯¼è‡´ keyPos æ··ä¹±
        /// </summary>
        public void SetCipher(StreamCipher? cipher)
        {
            _ingestPipeline.SetCipher(cipher);
            // VideoPipeline å’Œ AudioPipeline ä¸å†éœ€è¦ cipherï¼ˆè§£å¯†å·²åœ¨ IngestPipeline ä¸­å®Œæˆï¼‰
        }

        /// <summary>
        /// è®¾ç½®è§†é¢‘é…ç½®
        /// </summary>
        public void SetHeaders(byte[]? videoHeader, byte[]? audioHeader, VideoProfile[]? videoProfiles)
        {
            if (videoProfiles != null && videoProfiles.Length > 0)
            {
                _videoPipeline.SetStreamInfo(videoProfiles);
            }

            if (audioHeader != null)
            {
                _audioPipeline.SetHeader(audioHeader);
            }
        }

        /// <summary>
        /// è®¾ç½®è‡ªé€‚åº”æµç®¡ç†å™¨
        /// </summary>
        public void SetAdaptiveStreamManager(AdaptiveStreamManager? manager, Action<VideoProfile, VideoProfile?>? onProfileSwitch = null)
        {
            _videoPipeline.SetAdaptiveStreamManager(manager, onProfileSwitch);
        }

        /// <summary>
        /// è®¾ç½®è¯·æ±‚å…³é”®å¸§å›è°ƒ
        /// </summary>
        public void SetRequestKeyframeCallback(Func<Task>? callback)
        {
            _videoPipeline.SetRequestKeyframeCallback(callback);
        }

        /// <summary>
        /// è®¾ç½®å¸§ä¸¢å¤±å›è°ƒ
        /// </summary>
        public void SetFrameLossCallback(Action<int>? callback)
        {
            _audioPipeline.SetFrameLossCallback(callback);
        }

        /// <summary>
        /// è·å–å®Œæ•´ç»Ÿè®¡ä¿¡æ¯
        /// </summary>
        public PipelineStats GetStats()
        {
            return new PipelineStats
            {
                Ingest = _ingestPipeline.GetStats(),
                Video = _videoPipeline.GetStats(),
                Audio = _audioPipeline.GetStats(),
                Output = _outputPipeline.GetStats()
            };
        }

        /// <summary>
        /// åœæ­¢æ‰€æœ‰ Pipeline
        /// </summary>
        public void Stop()
        {
            _logger.LogInformation("ğŸ›‘ Stopping AVPipelineCoordinator...");
            _routerCts.Cancel();
        }

        #endregion

        #region Dispose

        public void Dispose()
        {
            Stop();

            try
            {
                Task.WaitAll(new[] { _packetRouterTask, _routerTask }, TimeSpan.FromMilliseconds(500));
            }
            catch { }

            _ingestPipeline.Dispose();
            _videoPipeline.Dispose();
            _audioPipeline.Dispose();
            _outputPipeline.Dispose();
            _routerCts.Dispose();

            _logger.LogInformation("âœ… AVPipelineCoordinator disposed");
        }

        #endregion
    }

    /// <summary>
    /// å®Œæ•´çš„ Pipeline ç»Ÿè®¡ä¿¡æ¯
    /// </summary>
    public struct PipelineStats
    {
        public IngestStats Ingest { get; set; }
        public VideoStats Video { get; set; }
        public AudioStats Audio { get; set; }
        public OutputStats Output { get; set; }

        public override string ToString()
        {
            return $"Ingest: Received={Ingest.TotalReceived}, Parsed={Ingest.TotalParsed}, " +
                   $"Video: Received={Video.TotalReceived}, Complete={Video.FramesComplete}, Dropped={Video.TotalDropped}, " +
                   $"Audio: Received={Audio.TotalReceived}, Complete={Audio.FramesComplete}, " +
                   $"Output: VideoSent={Output.VideoFramesSent}, AudioSent={Output.AudioFramesSent}";
        }
    }
}

