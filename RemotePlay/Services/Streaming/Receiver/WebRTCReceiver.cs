using RemotePlay.Models.PlayStation;
using SIPSorcery.Media;
using SIPSorcery.Net;
using System.Buffers;
using System.Buffers.Binary;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Linq;
using System.Linq.Expressions;
using System.Reflection;
using System.Runtime.InteropServices;
using Concentus;
using Concentus.Enums;
using Concentus.Structs;
using RemotePlay.Services.Statistics;
using RemotePlay.Services.Streaming.Receiver.Video;

namespace RemotePlay.Services.Streaming.Receiver
{
    /// <summary>
    /// WebRTC æ¥æ”¶å™¨ - é€šè¿‡ WebRTC å°† AV æµæ¨é€åˆ°æµè§ˆå™¨
    /// </summary>
    public sealed partial class WebRTCReceiver : IAVReceiver, IDisposable
    {
        private readonly ILogger<WebRTCReceiver> _logger;
        private readonly string _sessionId;
        private readonly LatencyStatisticsService? _latencyStats;
        private RTCPeerConnection? _peerConnection;
        private MediaStreamTrack? _videoTrack;
        private MediaStreamTrack? _audioTrack;
        private bool _disposed;
        private readonly string? _preferredVideoCodec;
        
        // RTP ç›¸å…³
        private uint _videoSsrc;
        private uint _audioSsrc;
        private ushort _videoSequenceNumber = 0;
        private ushort _audioSequenceNumber = 0;
        
        // âš ï¸ åºåˆ—å·ä¼šåœ¨ 65535 åè‡ªåŠ¨å›ç»•åˆ° 0ï¼Œè¿™æ˜¯ RTP åè®®çš„æ­£å¸¸è¡Œä¸º
        // ä½†éœ€è¦ç¡®ä¿å€¼åœ¨ ushort èŒƒå›´å†…ï¼ˆ0-65535ï¼‰
        private uint _videoTimestamp = 0;
        private uint _audioTimestamp = 0;
        private readonly DateTime _epochStart = DateTime.UtcNow;
        
        // RTP ä¼šè¯ï¼ˆé€šè¿‡ MediaStreamTrack è·å–ï¼‰- æœªä½¿ç”¨ï¼Œä¿ç•™ä»¥å¤‡å°†æ¥ä½¿ç”¨
        // private RTPSession? _videoRtpSession;
        // private RTPSession? _audioRtpSession;
        
        // è§†é¢‘å’ŒéŸ³é¢‘ç¼–ç å™¨
        private readonly VideoEncoderEndpoint _videoEncoder;
        private readonly AudioEncoderEndpoint _audioEncoder;
        
        // ç»Ÿè®¡ä¿¡æ¯
        private int _videoPacketCount;
        private int _audioPacketCount;
        private DateTime _startTime = DateTime.UtcNow;
        
        // æ—¶é—´æˆ³ä¼˜åŒ–ï¼šä½¿ç”¨åŸºäºå®é™…æ—¶é—´çš„å¢é‡ä»¥å‡å°‘å»¶è¿Ÿ
        private DateTime _lastVideoPacketTime = DateTime.UtcNow;
        private DateTime _lastAudioPacketTime = DateTime.UtcNow;
        
        // æ—¥å¿—é™æµï¼šé¿å…é‡å¤è­¦å‘Šæ—¥å¿—æ´—ç‰ˆ
        private DateTime _lastVideoPipelineWarningTime = DateTime.MinValue;
        private const int VIDEO_PIPELINE_WARNING_INTERVAL_SECONDS = 10; // æ¯ 10 ç§’æœ€å¤šè®°å½•ä¸€æ¬¡è­¦å‘Š
        
        // æ³¨æ„ï¼šä¸å†éœ€è¦ç­‰å¾…å…³é”®å¸§ï¼ŒWebRTC ä¼šè‡ªåŠ¨å¤„ç†å…³é”®å¸§æ£€æµ‹
        
        // è§†é¢‘ç¼–ç æ ¼å¼
        private string _detectedVideoFormat = "h264";
        
        // éŸ³é¢‘è§£ç ç›¸å…³ï¼ˆå‚ç…§ FfmpegMuxReceiverï¼‰
        private IOpusDecoder? _opusDecoder;
        private readonly object _opusDecoderLock = new object();
        private int _audioChannels = 2; // é»˜è®¤ 2 å£°é“
        private int _audioFrameSize = 480; // é»˜è®¤å¸§å¤§å°ï¼ˆ10ms @ 48kHzï¼‰
        private int _audioSampleRate = 48000;
        private int _sendingAudioChannels = 2; // å®é™…å‘é€åˆ°æµè§ˆå™¨çš„å£°é“æ•°
        private bool _forceStereoDownmix = false;
        private readonly object _opusEncoderLock = new object();
        private OpusEncoder? _stereoOpusEncoder;
        private int _stereoEncoderSampleRate = 48000;
        private byte[] _opusEncodeBuffer = new byte[4096];
        
        // âœ… éŸ³é¢‘ç¼–è§£ç å™¨é€‰æ‹©æ£€æµ‹
        private bool _useOpusDirect = true; // é»˜è®¤å°è¯•ç›´æ¥å‘é€ Opus
        private bool _opusCodecDetected = false; // æ˜¯å¦æ£€æµ‹åˆ° Opus è¢«é€‰ä¸­
        
        // âœ… éŸ³é¢‘é‡ç½®ååŒæ­¥æœºåˆ¶
        private bool _audioResetting = false; // æ˜¯å¦æ­£åœ¨é‡ç½®éŸ³é¢‘
        private int _audioFramesToSkip = 0; // é‡ç½®åéœ€è¦è·³è¿‡çš„å¸§æ•°
        private const int AUDIO_RESYNC_FRAMES = 1; // é‡ç½®åè·³è¿‡1å¸§ä»¥é‡æ–°åŒæ­¥ï¼ˆå‡å°‘éŸ³é¢‘ä¸­æ–­ï¼‰
        
        // âœ… æ—§çš„è§†é¢‘é˜Ÿåˆ—å·²ç§»é™¤ï¼Œç°åœ¨ä½¿ç”¨æ–°çš„æ¨¡å—åŒ– VideoPipeline
        
        // RTP å¸¸é‡
        private const int RTP_MTU = 1200; // RTP MTUï¼ˆé€šå¸¸æ¯” UDP MTU å°ï¼‰
        private const uint VIDEO_CLOCK_RATE = 90000; // H.264 è§†é¢‘æ—¶é’Ÿé¢‘ç‡
        private const uint AUDIO_CLOCK_RATE = 48000; // OPUS éŸ³é¢‘æ—¶é’Ÿé¢‘ç‡
        private const int VIDEO_FRAME_RATE_DEFAULT = 60; // é»˜è®¤ 60fpsï¼ˆç”¨äºåˆå§‹è®¡ç®—ï¼‰
        private const double VIDEO_TIMESTAMP_INCREMENT_DEFAULT = VIDEO_CLOCK_RATE / (double)VIDEO_FRAME_RATE_DEFAULT; // é»˜è®¤æ¯å¸§æ—¶é—´æˆ³å¢é‡
        
        // âœ… åŠ¨æ€å¸§ç‡æ£€æµ‹å’Œé€‚åº”
        private double _detectedFrameRate = VIDEO_FRAME_RATE_DEFAULT; // æ£€æµ‹åˆ°çš„å®é™…å¸§ç‡
        private double _videoTimestampIncrement = VIDEO_TIMESTAMP_INCREMENT_DEFAULT; // åŠ¨æ€è®¡ç®—çš„æ—¶é—´æˆ³å¢é‡
        private readonly Queue<double> _frameIntervalHistory = new Queue<double>(); // å¸§é—´éš”å†å²ï¼ˆç”¨äºè®¡ç®—å¹³å‡å¸§ç‡ï¼‰
        private const int FRAME_RATE_HISTORY_SIZE = 30; // ä¿ç•™æœ€è¿‘30å¸§çš„é—´éš”ç”¨äºè®¡ç®—å¸§ç‡
        private const double MIN_FRAME_RATE = 15.0; // æœ€å°å¸§ç‡ï¼ˆé¿å…å¼‚å¸¸å€¼ï¼‰
        private const double MAX_FRAME_RATE = 120.0; // æœ€å¤§å¸§ç‡ï¼ˆé¿å…å¼‚å¸¸å€¼ï¼‰
        private DateTime _lastFrameRateUpdateTime = DateTime.MinValue;
        private const int FRAME_RATE_UPDATE_INTERVAL_MS = 500; // æ¯500msæ›´æ–°ä¸€æ¬¡å¸§ç‡
        
        // âœ… åå•†åçš„åŠ¨æ€è´Ÿè½½ç±»å‹ï¼ˆé»˜è®¤ H264=96, HEVC=97ï¼Œåå•†æˆåŠŸåå°†è¦†ç›–ï¼‰
        private int _negotiatedPtH264 = 96;
        private int _negotiatedPtHevc = 97;
        
        // âœ… æ–°çš„æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“ï¼ˆå·²å®Œå…¨æ›¿æ¢æ—§æ–¹æ³•ï¼‰
        private VideoPipeline? _videoPipeline;
        
        public event EventHandler? OnDisconnected;
        
        // âœ… å…³é”®å¸§è¯·æ±‚äº‹ä»¶ï¼šå½“æ”¶åˆ°æ¥è‡ªæµè§ˆå™¨çš„ RTCP PLI/FIR åé¦ˆæ—¶è§¦å‘
        public event EventHandler? OnKeyframeRequested;
        
        // âœ… ICE Restart è¯·æ±‚äº‹ä»¶ï¼šå½“ ICE è¿æ¥æ–­å¼€æ—¶è§¦å‘
        public event EventHandler? OnIceRestartRequested;
        
        // å¸§ç´¢å¼•è·Ÿè¸ªï¼ˆç”¨äºå»¶æ—¶ç»Ÿè®¡ï¼‰
        private long _currentVideoFrameIndex = 0;
        private long _currentAudioFrameIndex = 0;
        
        // âœ… æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜åå°„æ–¹æ³•ï¼ˆä»…ç”¨äºéŸ³é¢‘ï¼Œè§†é¢‘å·²ä½¿ç”¨æ–°çš„æ¨¡å—åŒ–ç®¡é“ï¼‰
        private System.Reflection.MethodInfo? _cachedSendRtpRawAudioMethod;
        private bool _audioMethodsInitialized = false;
        private readonly object _audioMethodsLock = new object();
        
        // âœ… æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜è¿æ¥çŠ¶æ€ï¼Œå‡å°‘å±æ€§è®¿é—®å¼€é”€
        private RTCPeerConnectionState? _cachedConnectionState;
        private RTCIceConnectionState? _cachedIceState;
        private RTCSignalingState? _cachedSignalingState;
        private DateTime _lastStateCheckTime = DateTime.MinValue;
        private const int STATE_CACHE_MS = 50; // çŠ¶æ€ç¼“å­˜50msï¼ˆè§†é¢‘60fpsæ—¶æ¯å¸§16msï¼‰
        private readonly List<(object target, EventInfo @event, Delegate handler)> _rtcpFeedbackSubscriptions = new();
        private readonly HashSet<string> _rtcpSubscribedEventKeys = new(StringComparer.OrdinalIgnoreCase);
        private readonly object _rtcpFeedbackLock = new();
        private bool _rtcpFeedbackSubscribed;
        private DateTime _lastKeyframeRequestTime = DateTime.MinValue;
        private static readonly TimeSpan KEYFRAME_REQUEST_COOLDOWN = TimeSpan.FromMilliseconds(500);
        
        // âœ… è¿æ¥ä¿æ´»æœºåˆ¶ï¼šä½¿ç”¨ DataChannel keepaliveï¼ˆæœ€æœ‰æ•ˆï¼‰ï¼ŒSTUN Binding ä½œä¸ºå¤‡ç”¨
        private CancellationTokenSource? _keepaliveCts;
        private Task? _keepaliveTask;
        private DateTime _lastKeepaliveTime = DateTime.MinValue;
        private const int DATACHANNEL_KEEPALIVE_INTERVAL_MS = 5000; // DataChannel keepalive: 5ç§’ï¼ˆTURNè¿æ¥éœ€è¦æ›´é¢‘ç¹çš„keepaliveï¼Œé¿å…NATæ˜ å°„è¿‡æœŸï¼‰
        private DateTime _lastVideoOrAudioPacketTime = DateTime.UtcNow;
        private RTCDataChannel? _keepaliveDataChannel; // DataChannel ç”¨äº keepaliveï¼ˆæœ€æœ‰æ•ˆï¼‰
        private bool _dataChannelOpen = false; // âœ… DataChannel æ˜¯å¦å·²æ‰“å¼€
        private readonly object _dataChannelLock = new object();
        
        public WebRTCReceiver(
            string sessionId,
            RTCPeerConnection peerConnection,
            ILogger<WebRTCReceiver> logger,
            LatencyStatisticsService? latencyStats = null,
            string? preferredVideoCodec = null)
        {
            _sessionId = sessionId;
            _peerConnection = peerConnection;
            _logger = logger;
            _latencyStats = latencyStats;
            _preferredVideoCodec = NormalizePreferredVideoCodec(preferredVideoCodec);
            
            _videoEncoder = new VideoEncoderEndpoint();
            _audioEncoder = new AudioEncoderEndpoint();
            
            _logger.LogInformation("ğŸ¬ WebRTCReceiver åˆå§‹åŒ– - SessionId: {SessionId}", _sessionId);
            
            // ç”Ÿæˆéšæœº SSRC
            var random = new Random();
            _videoSsrc = (uint)random.Next(1, int.MaxValue);
            _audioSsrc = (uint)random.Next(1, int.MaxValue);
            
            // âœ… åˆå§‹åŒ–æ—¶ç¼“å­˜åå°„æ–¹æ³•ï¼ˆé¿å…æ¯æ¬¡å‘é€æ—¶æŸ¥æ‰¾ï¼‰
            InitializeAudioReflectionMethods();
            
            // ç›‘å¬è¿æ¥çŠ¶æ€å˜åŒ–ï¼ˆåŒæ—¶æ›´æ–°ç¼“å­˜ï¼‰
            _peerConnection.onconnectionstatechange += (state) =>
            {
                _cachedConnectionState = state;
                _lastStateCheckTime = DateTime.UtcNow;
                _logger.LogInformation("ğŸ“¡ WebRTC è¿æ¥çŠ¶æ€å˜åŒ–: {State} (å½“å‰è§†é¢‘åŒ…æ•°: {Count}, ICEçŠ¶æ€: {IceState})", 
                    state, _videoPacketCount, _peerConnection.iceConnectionState);
                if (state == RTCPeerConnectionState.connected)
                {
                    // è¿æ¥å»ºç«‹åï¼Œè·å– RTP é€šé“
                    InitializeRtpChannels();
                    
                    // âœ… è§£æ SDPï¼Œè·å–æµè§ˆå™¨åå•†çš„ H264/HEVC Payload Type
                    TryDetectNegotiatedVideoPayloadTypes();
                    
                    // âœ… æ£€æµ‹æµè§ˆå™¨å®é™…é€‰æ‹©çš„éŸ³é¢‘ç¼–è§£ç å™¨
                    DetectSelectedAudioCodec();
                    
                    // âœ… åˆå§‹åŒ–æ–°çš„æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“ï¼ˆåœ¨ SDP åå•†å®Œæˆåï¼‰
                    // å¦‚æœå·²ç»åœ¨ Answer è®¾ç½®åæå‰åˆå§‹åŒ–ï¼Œè¿™é‡Œä¸ä¼šé‡å¤åˆå§‹åŒ–
                    InitializeVideoPipeline();
                    
                    // âœ… å¯åŠ¨è¿æ¥ä¿æ´»æœºåˆ¶
                    StartKeepalive();
                }
                else if (state == RTCPeerConnectionState.failed || 
                    state == RTCPeerConnectionState.disconnected ||
                    state == RTCPeerConnectionState.closed)
                {
                    _logger.LogWarning("âš ï¸ WebRTC è¿æ¥æ–­å¼€: {State}", state);
                    // âœ… åœæ­¢ä¿æ´»æœºåˆ¶
                    StopKeepalive();
                    OnDisconnected?.Invoke(this, EventArgs.Empty);
                }
                else if (state == RTCPeerConnectionState.connected)
                {
                    // âœ… è¿æ¥æ¢å¤æ—¶ï¼Œå¦‚æœä¹‹å‰æ˜¯æ–­å¼€çŠ¶æ€ï¼Œå¯èƒ½éœ€è¦è¯·æ±‚å…³é”®å¸§
                    // è¿™å¯ä»¥å¤„ç†ç½‘ç»œä¸­æ–­åçš„æ¢å¤åœºæ™¯
                    if (_cachedConnectionState == RTCPeerConnectionState.disconnected ||
                        _cachedConnectionState == RTCPeerConnectionState.failed)
                    {
                        _logger.LogInformation("ğŸ”„ è¿æ¥å·²æ¢å¤ï¼Œè¯·æ±‚å…³é”®å¸§ä»¥åŒæ­¥è§†é¢‘æµ");
                        OnKeyframeRequested?.Invoke(this, EventArgs.Empty);
                    }
                }
            };
            
            // ç›‘å¬ ICE è¿æ¥çŠ¶æ€å˜åŒ–
            _peerConnection.oniceconnectionstatechange += (state) =>
            {
                _cachedIceState = state;
                _lastStateCheckTime = DateTime.UtcNow;
                
                // å¦‚æœ ICE å·²è¿æ¥ï¼Œä½† connectionState è¿˜æ˜¯ newï¼Œè®°å½•è­¦å‘Š
                if (state == RTCIceConnectionState.connected &&
                    _peerConnection.connectionState == RTCPeerConnectionState.@new)
                {
                    _logger.LogWarning("âš ï¸ ICE å·²è¿æ¥ä½† connectionState ä»æ˜¯ newï¼Œè¿™å¯èƒ½å½±å“è§†é¢‘å‘é€");
                }
                
                // âœ… å¦‚æœ ICE æ–­å¼€ï¼Œå»¶è¿Ÿåå°è¯• ICE Restartï¼ˆé¿å…çŸ­æš‚æŠ–åŠ¨ï¼‰
                if (state == RTCIceConnectionState.disconnected || 
                    state == RTCIceConnectionState.failed)
                {
                    _logger.LogWarning("âš ï¸ ICE è¿æ¥æ–­å¼€: {State}ï¼Œå°†åœ¨å»¶è¿Ÿåå°è¯• ICE Restart", state);
                    StopKeepalive();
                    
                    // âœ… å»¶è¿Ÿè§¦å‘ ICE Restartï¼ˆé¿å…çŸ­æš‚æŠ–åŠ¨ï¼Œdisconnected æŒç»­ > 10ç§’æ‰è§¦å‘ï¼‰
                    _ = Task.Run(async () =>
                    {
                        await Task.Delay(10000); // ç­‰å¾… 10 ç§’
                        
                        // âœ… å†æ¬¡æ£€æŸ¥çŠ¶æ€ï¼Œç¡®è®¤ä»ç„¶æ–­å¼€
                        if (_peerConnection != null && !_disposed)
                        {
                            var currentIceState = _peerConnection.iceConnectionState;
                            if (currentIceState == RTCIceConnectionState.disconnected || 
                                currentIceState == RTCIceConnectionState.failed)
                            {
                                _logger.LogInformation("ğŸ”„ ICE è¿æ¥æŒç»­æ–­å¼€ï¼Œè§¦å‘ ICE Restart");
                                OnIceRestartRequested?.Invoke(this, EventArgs.Empty);
                            }
                        }
                    });
                }
                else if (state == RTCIceConnectionState.closed)
                {
                    _logger.LogWarning("âš ï¸ ICE è¿æ¥å·²å…³é—­: {State}", state);
                    StopKeepalive();
                }
                else if (state == RTCIceConnectionState.connected &&
                         _peerConnection.connectionState == RTCPeerConnectionState.connected)
                {
                    StartKeepalive();
                }
            };
            
            // ç›‘å¬ ICE gathering çŠ¶æ€å˜åŒ–
            _peerConnection.onicegatheringstatechange += (state) =>
            {
                // ICE gathering çŠ¶æ€å˜åŒ–æ—¥å¿—å·²ç§»é™¤
            };
            
            // ç›‘å¬ ICE candidates
            _peerConnection.onicecandidate += (candidate) =>
            {
                // ICE candidate æ—¥å¿—å·²ç§»é™¤
            };
            
            // âœ… ç›‘å¬ RTCP åé¦ˆï¼ˆPLI/FIR å…³é”®å¸§è¯·æ±‚ï¼‰
            InitializeRTCPFeedback();
            
            // åˆ›å»ºè§†é¢‘å’ŒéŸ³é¢‘è½¨é“
            InitializeTracks();
        }
        
        /// <summary>
        /// ä» SDP ä¸­è§£æ H264/H265 çš„åŠ¨æ€è´Ÿè½½ç±»å‹ï¼ˆpayload typeï¼‰
        /// </summary>
        private void TryDetectNegotiatedVideoPayloadTypes()
        {
            try
            {
                string sdp = "";
                if (_peerConnection?.localDescription?.sdp != null)
                {
                    sdp = _peerConnection.localDescription.sdp.ToString() ?? "";
                }
                // è‹¥æœ¬åœ°ä¸ºç©ºï¼Œå°è¯•è¿œç«¯
                if (string.IsNullOrWhiteSpace(sdp) && _peerConnection?.remoteDescription?.sdp != null)
                {
                    sdp = _peerConnection.remoteDescription.sdp.ToString() ?? "";
                }
                if (string.IsNullOrWhiteSpace(sdp))
                {
                    return;
                }
                
                // è§£æ a=rtpmap:<pt> H264/90000 æˆ– H265/90000
                var lines = sdp.Split('\n');
                foreach (var raw in lines)
                {
                    var line = raw.Trim();
                    if (!line.StartsWith("a=rtpmap:", StringComparison.OrdinalIgnoreCase))
                        continue;
                    
                    // a=rtpmap:96 H264/90000
                    var parts = line.Substring("a=rtpmap:".Length).Split(' ');
                    if (parts.Length < 2) continue;
                    if (!int.TryParse(parts[0], out var pt)) continue;
                    
                    var codecPart = parts[1].ToLowerInvariant();
                    if (codecPart.StartsWith("h264/"))
                    {
                        _negotiatedPtH264 = pt;
                        _logger.LogInformation("âœ… åå•†çš„ H264 PayloadType: {Pt}", pt);
                    }
                    else if (codecPart.StartsWith("h265/") || codecPart.StartsWith("hevc/"))
                    {
                        _negotiatedPtHevc = pt;
                        _logger.LogInformation("âœ… åå•†çš„ HEVC PayloadType: {Pt}", pt);
                    }
                }
            }
            catch (Exception ex)
            {
                _logger.LogDebug(ex, "âš ï¸ è§£æè§†é¢‘ PayloadType å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨é»˜è®¤å€¼ (H264=96, HEVC=97)");
            }
        }
        
        /// <summary>
        /// æ£€æµ‹æµè§ˆå™¨å®é™…é€‰æ‹©çš„éŸ³é¢‘ç¼–è§£ç å™¨
        /// </summary>
        private void DetectSelectedAudioCodec()
        {
            try
            {
                if (_peerConnection == null) return;
                
                // è·å– remote description (Answer SDP)
                var remoteDescription = _peerConnection.remoteDescription;
                if (remoteDescription == null || remoteDescription.sdp == null)
                {
                    _logger.LogWarning("âš ï¸ æ— æ³•æ£€æµ‹éŸ³é¢‘ç¼–è§£ç å™¨ï¼šremote description ä¸ºç©º");
                    _useOpusDirect = false; // å›é€€åˆ°è½¬ç 
                    return;
                }
                
                // âœ… SDP å¯¹è±¡éœ€è¦è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                string sdp = remoteDescription.sdp.ToString() ?? "";
                if (string.IsNullOrEmpty(sdp))
                {
                    _logger.LogWarning("âš ï¸ æ— æ³•æ£€æµ‹éŸ³é¢‘ç¼–è§£ç å™¨ï¼šSDP å­—ç¬¦ä¸²ä¸ºç©º");
                    _useOpusDirect = false; // å›é€€åˆ°è½¬ç 
                    return;
                }
                
                // æ£€æŸ¥æ˜¯å¦åŒ…å« Opus
                bool hasOpus = sdp.Contains("opus") || sdp.Contains("111");
                bool hasPCMU = sdp.Contains("PCMU") || sdp.Contains("a=rtpmap:0");
                
                _logger.LogInformation("ğŸ”Š æ£€æµ‹åˆ°çš„éŸ³é¢‘ç¼–è§£ç å™¨: Opus={Opus}, PCMU={PCMU}", hasOpus, hasPCMU);
                
                // æŸ¥æ‰¾ m=audio è¡Œï¼Œæ£€æŸ¥æµè§ˆå™¨é€‰æ‹©çš„ç¼–è§£ç å™¨
                var lines = sdp.Split('\n');
                bool inAudioSection = false;
                string? selectedPayloadType = null;
                
                foreach (var line in lines)
                {
                    var trimmed = line.Trim();
                    if (trimmed.StartsWith("m=audio"))
                    {
                        inAudioSection = true;
                        // m=audio æ ¼å¼: m=audio <port> <proto> <fmt> <fmt> ...
                        // ç¬¬ä¸€ä¸ª fmt æ˜¯æµè§ˆå™¨é€‰æ‹©çš„ç¼–è§£ç å™¨
                        var parts = trimmed.Split(' ');
                        if (parts.Length > 3)
                        {
                            selectedPayloadType = parts[3]; // ç¬¬ä¸€ä¸ªæ ¼å¼ï¼ˆæµè§ˆå™¨é€‰æ‹©çš„ï¼‰
                            _logger.LogInformation("ğŸ”Š m=audio è¡Œç¬¬ä¸€ä¸ªæ ¼å¼ï¼ˆæµè§ˆå™¨é€‰æ‹©ï¼‰: {Format}", selectedPayloadType);
                        }
                    }
                    else if (trimmed.StartsWith("m=") && !trimmed.StartsWith("m=audio"))
                    {
                        inAudioSection = false;
                    }
                    else if (inAudioSection && trimmed.StartsWith("a=rtpmap:"))
                    {
                        // a=rtpmap:111 opus/48000/2 æˆ– a=rtpmap:0 PCMU/8000/1
                        var parts = trimmed.Split(' ');
                        if (parts.Length > 1)
                        {
                            var payloadTypeStr = parts[0].Substring("a=rtpmap:".Length);
                            if (payloadTypeStr == selectedPayloadType)
                            {
                                // è¿™æ˜¯æµè§ˆå™¨é€‰æ‹©çš„ç¼–è§£ç å™¨
                                if (trimmed.Contains("opus"))
                                {
                                    _opusCodecDetected = true;
                                    _logger.LogInformation("âœ… æµè§ˆå™¨é€‰æ‹©äº† Opusï¼ˆé«˜è´¨é‡ï¼‰: {Line}", trimmed);
                                }
                                else if (trimmed.Contains("PCMU") || payloadTypeStr == "0")
                                {
                                    _opusCodecDetected = false;
                                    _logger.LogWarning("âš ï¸ æµè§ˆå™¨é€‰æ‹©äº† PCMU: {Line}", trimmed);
                                }
                                else
                                {
                                    _opusCodecDetected = false;
                                    _logger.LogWarning("âš ï¸ æµè§ˆå™¨é€‰æ‹©äº†å…¶ä»–ç¼–è§£ç å™¨: {Line}", trimmed);
                                }
                            }
                        }
                    }
                }
                
                // âœ… ä¼˜åŒ–ç­–ç•¥ï¼šå³ä½¿æµè§ˆå™¨é€‰æ‹©äº† PCMUï¼Œä¹Ÿä¼˜å…ˆå°è¯•å‘é€ Opus
                // ç°ä»£æµè§ˆå™¨é€šå¸¸èƒ½å¤„ç† Opusï¼Œå³ä½¿ SDP ä¸­ä¹Ÿé€‰æ‹©äº† PCMU
                _useOpusDirect = _opusCodecDetected;
                
                // âœ… å¦‚æœæµè§ˆå™¨é€‰æ‹©äº† PCMUï¼Œæ ‡è®°ä¸ºéœ€è¦å°è¯• Opusï¼ˆé«˜è´¨é‡ï¼‰
                if (hasPCMU && selectedPayloadType == "0")
                {
                    _opusCodecDetected = false;
                    // ä¸å¼ºåˆ¶ä½¿ç”¨è½¬ç ï¼Œè€Œæ˜¯å°è¯•å‘é€ Opusï¼ˆé«˜è´¨é‡ï¼‰
                    _useOpusDirect = false; // æ ‡è®°ä¸º falseï¼Œä½†ä¼šåœ¨å‘é€æ—¶å°è¯• Opus
                    _logger.LogInformation("ğŸ”„ æµè§ˆå™¨é€‰æ‹©äº† PCMUï¼Œä½†å°†å°è¯•å‘é€ Opus ä»¥è·å¾—é«˜è´¨é‡éŸ³è´¨");
                }
                
                // âœ… å¦‚æœæ£€æµ‹åˆ° Opusï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ ‡è®°ä¸ºéœ€è¦å°è¯• Opus
                if (_opusCodecDetected)
                {
                    _useOpusDirect = true;
                }
                else
                {
                    // æœªæ£€æµ‹åˆ° Opusï¼Œä½†ä¼šå°è¯•å‘é€ Opusï¼ˆé€šè¿‡ TrySendOpusReencodedï¼‰
                    _useOpusDirect = false;
                }
                
                if (!_useOpusDirect)
                {
                    _logger.LogWarning("âš ï¸ æµè§ˆå™¨é€‰æ‹©äº† PCMUï¼ˆ8kHzï¼‰ï¼Œå°†å°è¯•å‘é€ Opus ä»¥è·å¾—é«˜è´¨é‡éŸ³è´¨ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨è½¬ç æ–¹æ¡ˆ");
                }
                else
                {
                    _logger.LogInformation("âœ… æµè§ˆå™¨é€‰æ‹©äº† Opusï¼ˆ48kHzï¼Œé«˜è´¨é‡ç¼–ç ï¼‰ï¼Œå°†ç›´æ¥å‘é€ Opus æ•°æ®ï¼Œæ— éœ€è½¬ç ");
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ æ£€æµ‹éŸ³é¢‘ç¼–è§£ç å™¨å¤±è´¥ï¼Œé»˜è®¤ä½¿ç”¨è½¬ç æ–¹æ¡ˆ");
                _useOpusDirect = false; // å‡ºé”™æ—¶å›é€€åˆ°è½¬ç 
            }
        }
        
        private void InitializeTracks()
        {
            // âœ… æ›´æ–°ï¼šChrome 136+ é»˜è®¤æ”¯æŒ WebRTC H265/HEVC ç¼–ç 
            // å› æ­¤åŒæ—¶æä¾› H.264 å’Œ HEVC æ”¯æŒï¼Œè®©æµè§ˆå™¨é€‰æ‹©å®ƒæ”¯æŒçš„æ ¼å¼
            // Chrome 136+ ä¼šé€‰æ‹© HEVCï¼Œæ—§ç‰ˆæœ¬æµè§ˆå™¨ä¼šé€‰æ‹© H.264
            
            var h264Format = new SDPAudioVideoMediaFormat(
                SDPMediaTypesEnum.video,
                96,
                "H264",
                90000
            );
            
            // âœ… æ·»åŠ  HEVC æ”¯æŒï¼ˆChrome 136+ æ”¯æŒï¼‰
            var hevcFormat = new SDPAudioVideoMediaFormat(
                SDPMediaTypesEnum.video,
                97,
                "H265",
                90000
            );
            
            // åŒæ—¶æä¾› H.264 å’Œ HEVCï¼Œè®©æµè§ˆå™¨é€‰æ‹©
            // Chrome 136+ ä¼šé€‰æ‹© HEVCï¼Œæ—§ç‰ˆæœ¬æµè§ˆå™¨ä¼šé€‰æ‹© H.264
            var videoFormats = BuildVideoFormats(h264Format, hevcFormat);
            
            
            _videoTrack = new MediaStreamTrack(
                SDPMediaTypesEnum.video,
                false,
                videoFormats,
                MediaStreamStatusEnum.SendOnly
            );
            
            // âœ… ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨ Opusï¼Œè·å¾—æœ€é«˜éŸ³è´¨ï¼ˆ48kHzï¼Œé«˜è´¨é‡ç¼–ç ï¼‰
            // Opus æ˜¯ WebRTC æ ‡å‡†ç¼–è§£ç å™¨ï¼Œæ‰€æœ‰ç°ä»£æµè§ˆå™¨éƒ½æ”¯æŒ
            // æä¾› PCMU ä½œä¸ºå¤‡ç”¨ä»¥ç¡®ä¿å…¼å®¹æ€§ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ Opus
            var initialAudioChannels = Math.Max(1, _sendingAudioChannels);
            var opusFormat = new SDPAudioVideoMediaFormat(
                SDPMediaTypesEnum.audio,
                111,
                "opus",
                48000,
                initialAudioChannels
            );
            
            // æä¾› PCMU ä½œä¸ºå¤‡ç”¨ï¼ˆå…¼å®¹æ€§ï¼Œä½†ä¼šé™ä½éŸ³è´¨ï¼‰
            var pcmuFormat = new SDPAudioVideoMediaFormat(
                SDPMediaTypesEnum.audio,
                0,
                "PCMU",
                8000
            );
            
            // âœ… ä¼˜å…ˆæä¾› Opusï¼Œç¡®ä¿æµè§ˆå™¨ä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡ç¼–ç 
            // å¦‚æœæµè§ˆå™¨ä¸æ”¯æŒ Opusï¼Œä¼šå›é€€åˆ° PCMUï¼ˆç„¶åä½¿ç”¨è½¬ç ï¼‰
            _audioTrack = new MediaStreamTrack(
                SDPMediaTypesEnum.audio,
                false,
                new List<SDPAudioVideoMediaFormat> { 
                    opusFormat,
                    //pcmuFormat 
                 },
                MediaStreamStatusEnum.SendRecv
            );
            
            
            // âœ… æ·»åŠ è§†é¢‘å’ŒéŸ³é¢‘è½¨é“
            _peerConnection?.addTrack(_videoTrack);
            _peerConnection?.addTrack(_audioTrack);
            
            // âœ… å»¶è¿Ÿåˆå§‹åŒ– VideoPipelineï¼šå°†åœ¨è¿æ¥å»ºç«‹åï¼ŒSDPåå•†å®Œæˆæ—¶åˆå§‹åŒ–ï¼ˆç¡®ä¿ payload types æ­£ç¡®ï¼‰
            // åœ¨ onconnectionstatechange ä¸­åˆå§‹åŒ–ï¼ˆè¿æ¥å»ºç«‹åï¼‰
        }
        
        /// <summary>
        /// åˆå§‹åŒ–æ–°çš„æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“
        /// åº”è¯¥åœ¨è¿æ¥å»ºç«‹åã€SDPåå•†å®Œæˆåè°ƒç”¨ï¼ˆç¡®ä¿ payload types æ­£ç¡®ï¼‰
        /// </summary>
        /// <summary>
        /// âœ… æå‰åˆå§‹åŒ–è§†é¢‘ç®¡é“ï¼ˆåœ¨ Answer è®¾ç½®åï¼Œä¸ç­‰å¾…è¿æ¥å»ºç«‹ï¼‰
        /// è¿™å¯¹äºå¼ºåˆ¶ä½¿ç”¨ TURN çš„åœºæ™¯å¾ˆé‡è¦ï¼Œå› ä¸ºå³ä½¿ ICE è¿æ¥å¤±è´¥ï¼Œè§†é¢‘ç®¡é“ä¹Ÿåº”è¯¥åˆå§‹åŒ–
        /// </summary>
        public void InitializeVideoPipelineEarly()
        {
            if (_videoPipeline != null || _videoTrack == null)
            {
                return;
            }
            
            try
            {
                // âœ… åœ¨ Answer è®¾ç½®åï¼Œå°è¯•æ£€æµ‹åå•†çš„ Payload Type
                // å¦‚æœ remote description å·²è®¾ç½®ï¼Œå¯ä»¥æå‰æ£€æµ‹
                if (_peerConnection?.remoteDescription != null)
                {
                    TryDetectNegotiatedVideoPayloadTypes();
                    DetectSelectedAudioCodec();
                }
                
                // âœ… åˆå§‹åŒ–è§†é¢‘ç®¡é“ï¼ˆå³ä½¿ Payload Type è¿˜æœªæ£€æµ‹åˆ°ï¼Œä¹Ÿå¯ä»¥å…ˆåˆå§‹åŒ–ï¼‰
                // VideoPipeline ä¼šåœ¨åç»­æ”¶åˆ°è§†é¢‘æ•°æ®æ—¶ä½¿ç”¨æ­£ç¡®çš„ Payload Type
                _videoPipeline = new VideoPipeline(
                    _logger,
                    _peerConnection,
                    _videoTrack,
                    _videoSsrc,
                    _detectedVideoFormat,
                    _negotiatedPtH264,
                    _negotiatedPtHevc);
                
                // è®¾ç½®ç»Ÿè®¡å›è°ƒ
                _videoPipeline.SetOnPacketSent(frameIndex => 
                {
                    _latencyStats?.RecordPacketSent(_sessionId, "video", frameIndex);
                });
                
                _logger.LogInformation("âœ… æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“å·²æå‰åˆå§‹åŒ– (SSRC={Ssrc}, H264={H264}, HEVC={Hevc})", 
                    _videoSsrc, _negotiatedPtH264, _negotiatedPtHevc);
            }
            catch (Exception ex)
            {
                _logger.LogWarning(ex, "âš ï¸ æå‰åˆå§‹åŒ–è§†é¢‘å¤„ç†ç®¡é“å¤±è´¥ï¼Œå°†åœ¨è¿æ¥å»ºç«‹æ—¶é‡è¯•");
                _videoPipeline?.Dispose();
                _videoPipeline = null;
            }
        }
        
        private void InitializeVideoPipeline()
        {
            if (_videoPipeline != null || _videoTrack == null)
            {
                return;
            }
            
            try
            {
                _videoPipeline = new VideoPipeline(
                    _logger,
                    _peerConnection,
                    _videoTrack,
                    _videoSsrc,
                    _detectedVideoFormat,
                    _negotiatedPtH264,
                    _negotiatedPtHevc);
                
                // è®¾ç½®ç»Ÿè®¡å›è°ƒ
                _videoPipeline.SetOnPacketSent(frameIndex => 
                {
                    _latencyStats?.RecordPacketSent(_sessionId, "video", frameIndex);
                });
                
                _logger.LogInformation("âœ… æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“å·²åˆå§‹åŒ– (SSRC={Ssrc}, H264={H264}, HEVC={Hevc})", 
                    _videoSsrc, _negotiatedPtH264, _negotiatedPtHevc);
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ åˆå§‹åŒ–è§†é¢‘å¤„ç†ç®¡é“å¤±è´¥");
                _videoPipeline?.Dispose();
                _videoPipeline = null;
            }
        }

        private static string? NormalizePreferredVideoCodec(string? codec)
        {
            if (string.IsNullOrWhiteSpace(codec))
            {
                return null;
            }

            var normalized = codec.Trim().ToLowerInvariant();
            return normalized switch
            {
                "h264" => "h264",
                "avc" => "h264",
                "h265" => "h265",
                "hevc" => "h265",
                _ => null
            };
        }

        private List<SDPAudioVideoMediaFormat> BuildVideoFormats(
            SDPAudioVideoMediaFormat h264Format,
            SDPAudioVideoMediaFormat hevcFormat)
        {
            if (_preferredVideoCodec != null && (_preferredVideoCodec.ToLower() == "h264" || _preferredVideoCodec.ToLower() == "avc"))
            {
                _logger.LogInformation("ğŸ¯ WebRTC è§†é¢‘è½¨é“ä½¿ç”¨é¦–é€‰ç¼–ç ï¼šH.264");
                return new List<SDPAudioVideoMediaFormat> { h264Format };
            }

            if (_preferredVideoCodec != null && (_preferredVideoCodec.ToLower() == "h265" || _preferredVideoCodec.ToLower() == "hevc"))
            {
                _logger.LogInformation("ğŸ¯ WebRTC è§†é¢‘è½¨é“ä½¿ç”¨é¦–é€‰ç¼–ç ï¼šH.265/HEVC");
                return new List<SDPAudioVideoMediaFormat> { hevcFormat,h264Format };
            }

            // æœªæŒ‡å®šæ—¶ï¼Œä¿æŒé»˜è®¤é¡ºåºï¼šHEVC ä¼˜å…ˆï¼ŒH.264 å¤‡ç”¨
            return new List<SDPAudioVideoMediaFormat> { hevcFormat, h264Format };
        }
        
        public void SetVideoCodec(string codec)
        {
            _detectedVideoFormat = codec.ToLower();
            _logger.LogInformation("ğŸ“¹ è§†é¢‘ç¼–ç æ ¼å¼: {Codec}", codec);
        }
        
        public void SetAudioCodec(string codec)
        {
            // éŸ³é¢‘ç¼–ç æ ¼å¼å·²è®¾ç½®
        }
        
        public void EnterWaitForIdr()
        {
            // âœ… å½“éœ€è¦ç­‰å¾…å…³é”®å¸§æ—¶ï¼Œè§¦å‘å…³é”®å¸§è¯·æ±‚äº‹ä»¶
            // è¿™é€šå¸¸å‘ç”Ÿåœ¨åˆ‡æ¢æ¥æ”¶å™¨æˆ–é‡æ–°è¿æ¥æ—¶
            _logger.LogInformation("ğŸ¬ è¿›å…¥ç­‰å¾… IDR æ¨¡å¼ï¼Œè¯·æ±‚å…³é”®å¸§");
            OnKeyframeRequested?.Invoke(this, EventArgs.Empty);
        }
        
        public void OnStreamInfo(byte[] videoHeader, byte[] audioHeader)
        {
            try
            {
                // å¤„ç†è§†é¢‘ headerï¼ˆæ£€æµ‹ç¼–ç æ ¼å¼ï¼‰
                if (videoHeader != null && videoHeader.Length > 0)
                {
                    string? detectedCodec = DetectCodecFromVideoHeader(videoHeader);
                    if (detectedCodec != null && detectedCodec != _detectedVideoFormat)
                    {
                        _detectedVideoFormat = detectedCodec;
                    }
                }
                
                // âš ï¸ å‚ç…§ FfmpegMuxReceiverï¼šä» audioHeader è¯»å–éŸ³é¢‘å‚æ•°
                if (audioHeader == null || audioHeader.Length < 10)
                {
                    if (audioHeader == null)
                    {
                        _logger.LogWarning("âš ï¸ OnStreamInfo: audioHeader ä¸º nullï¼Œè·³è¿‡éŸ³é¢‘åˆå§‹åŒ–");
                    }
                    else
                    {
                        _logger.LogWarning("âš ï¸ OnStreamInfo: audioHeader é•¿åº¦ä¸è¶³ ({Length} < 10)ï¼Œè·³è¿‡éŸ³é¢‘åˆå§‹åŒ–", audioHeader.Length);
                    }
                    return;
                }
                
                // audioHeader æœ‰æ•ˆï¼Œç»§ç»­å¤„ç†
                int channels = ParseAudioChannels(audioHeader);
                int bitsPerSample = ParseBitsPerSample(audioHeader);
                int rate = ParseSampleRate(audioHeader);
                int frameSize = ParseFrameSize(audioHeader);
                
                // ä¿å­˜å¸§å¤§å°ï¼ˆç”¨äº PCM ç¼“å†²åŒºå¤§å°è®¡ç®—ï¼‰
                if (frameSize > 0)
                {
                    _audioFrameSize = frameSize;
                }
                int previousSourceChannels = _audioChannels;

                if (channels > 0)
                {
                    if (_audioPacketCount < 5 || previousSourceChannels != channels)
                    {
                        _logger.LogInformation("ğŸ”Š éŸ³é¢‘å‚æ•°ï¼šchannels={Channels}, bits={Bits}, rate={Rate}Hz, frameSize={FrameSize}", channels, bitsPerSample, rate, frameSize);
                    }

                    if (channels != 2 && (_audioPacketCount < 5 || previousSourceChannels != channels))
                    {
                        _logger.LogWarning("âš ï¸ ä¸»æœºæŠ¥å‘ŠéŸ³é¢‘å£°é“æ•°ä¸º {Channels}ï¼Œå»ºè®®åœ¨ä¸»æœºç«¯å¼€å¯ç«‹ä½“å£°ä¸‹æ··æˆ–è®¾ç½®ä¸º 2 å£°é“è¾“å‡º", channels);
                    }

                    _audioChannels = Math.Clamp(channels, 1, 2);
                    _forceStereoDownmix = false;
                    _useOpusDirect = true;
                    _sendingAudioChannels = 2;
                }

                // åˆå§‹åŒ– Opus è§£ç å™¨ï¼ˆå‚ç…§ FfmpegMuxReceiverï¼‰
                if (rate > 0 && channels > 0)
                {
                    lock (_opusDecoderLock)
                    {
                        // å¦‚æœå‚æ•°æ”¹å˜ï¼Œé‡æ–°åˆå§‹åŒ–è§£ç å™¨
                        bool needReinit = false;
                        if (rate != _audioSampleRate)
                        {
                            _audioSampleRate = rate;
                            needReinit = true;
                        }
                        if (channels != _audioChannels)
                        {
                            _audioChannels = channels;
                            needReinit = true;
                        }
                        int targetChannels = Math.Clamp(channels, 1, 2);
                        if (targetChannels != _audioChannels)
                        {
                            _audioChannels = targetChannels;
                            needReinit = true;
                        }

                        if (needReinit || _opusDecoder == null)
                        {
                            _opusDecoder?.Dispose();
                            try
                            {
                                _opusDecoder = OpusCodecFactory.CreateDecoder(_audioSampleRate, _audioChannels);
                            }
                            catch (Exception ex)
                            {
                                _logger.LogError(ex, "âŒ åˆå§‹åŒ– Opus è§£ç å™¨å¤±è´¥");
                                _opusDecoder = null;
                            }
                        }
                    }
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ å¤„ç† StreamInfo å¤±è´¥");
            }
        }

        /// <summary>
        /// åˆå§‹åŒ–éŸ³é¢‘åå°„æ–¹æ³•ç¼“å­˜ï¼ˆä»…ç”¨äºéŸ³é¢‘ï¼Œè§†é¢‘å·²ä½¿ç”¨æ–°çš„æ¨¡å—åŒ–ç®¡é“ï¼‰
        /// </summary>
        private void InitializeAudioReflectionMethods()
        {
            lock (_audioMethodsLock)
            {
                if (_audioMethodsInitialized || _peerConnection == null)
                    return;
                
                try
                {
                    var peerConnectionType = _peerConnection.GetType();
                    
                    // æŸ¥æ‰¾ SendRtpRaw ç›¸å…³æ–¹æ³•ï¼ˆä»…ç”¨äºéŸ³é¢‘ï¼‰
                var sendRtpRawMethods = peerConnectionType.GetMethods(System.Reflection.BindingFlags.Public | System.Reflection.BindingFlags.Instance)
                        .Where(m => m.Name == "SendRtpRaw" || m.Name == "SendRtpPacket")
                    .ToList();
                
                if (sendRtpRawMethods.Count == 0)
                {
                    var baseType = peerConnectionType.BaseType;
                    if (baseType != null)
                    {
                        sendRtpRawMethods = baseType.GetMethods(System.Reflection.BindingFlags.Public | System.Reflection.BindingFlags.Instance)
                                .Where(m => m.Name == "SendRtpRaw" || m.Name == "SendRtpPacket")
                            .ToList();
                    }
                }
                
                    // æŸ¥æ‰¾ SendRtpRaw(byte[], int) - ç”¨äºéŸ³é¢‘
                foreach (var method in sendRtpRawMethods)
                    {
                        var parameters = method.GetParameters();
                        if (parameters.Length == 2 && 
                            parameters[0].ParameterType == typeof(byte[]) &&
                            parameters[1].ParameterType == typeof(int))
                            {
                                _cachedSendRtpRawAudioMethod = method;
                            break;
                        }
                    }
                    
                    _audioMethodsInitialized = true;
                    _logger.LogDebug("âœ… éŸ³é¢‘åå°„æ–¹æ³•ç¼“å­˜åˆå§‹åŒ–å®Œæˆ: SendRtpRaw={HasRtpRaw}", 
                        _cachedSendRtpRawAudioMethod != null);
                    }
                    catch (Exception ex)
                    {
                    _logger.LogWarning(ex, "âš ï¸ åˆå§‹åŒ–éŸ³é¢‘åå°„æ–¹æ³•ç¼“å­˜å¤±è´¥ï¼Œå°†ä½¿ç”¨è¿è¡Œæ—¶æŸ¥æ‰¾");
                }
            }
        }
        
        /// <summary>
        /// è·å–ç¼“å­˜çš„è¿æ¥çŠ¶æ€ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘å±æ€§è®¿é—®ï¼‰
        /// </summary>
        private (RTCPeerConnectionState connectionState, RTCIceConnectionState iceState, RTCSignalingState signalingState) GetCachedConnectionState()
        {
            var now = DateTime.UtcNow;
            if (_cachedConnectionState.HasValue && 
                _cachedIceState.HasValue && 
                _cachedSignalingState.HasValue &&
                (now - _lastStateCheckTime).TotalMilliseconds < STATE_CACHE_MS)
            {
                // ä½¿ç”¨ç¼“å­˜çš„çŠ¶æ€
                return (_cachedConnectionState.Value, _cachedIceState.Value, _cachedSignalingState.Value);
            }
            
            // æ›´æ–°ç¼“å­˜
            if (_peerConnection != null)
            {
                _cachedConnectionState = _peerConnection.connectionState;
                _cachedIceState = _peerConnection.iceConnectionState;
                _cachedSignalingState = _peerConnection.signalingState;
                _lastStateCheckTime = now;
                return (_cachedConnectionState.Value, _cachedIceState.Value, _cachedSignalingState.Value);
            }
            
            // å¦‚æœ peerConnection ä¸º nullï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆæ­£å¸¸æƒ…å†µä¸‹ä¸åº”è¯¥å‘ç”Ÿï¼‰
            // RTCSignalingState æ²¡æœ‰ @new å€¼ï¼Œä½¿ç”¨ stable ä½œä¸ºé»˜è®¤å€¼
            return (RTCPeerConnectionState.@new, RTCIceConnectionState.@new, RTCSignalingState.stable);
        }
        
        public void Dispose()
        {
            if (_disposed) return;
            _disposed = true;
            
            _logger.LogInformation("ğŸ›‘ WebRTCReceiver æ­£åœ¨é‡Šæ”¾èµ„æº - è§†é¢‘åŒ…: {Video}, éŸ³é¢‘åŒ…: {Audio}", 
                _videoPacketCount, _audioPacketCount);
            
            try
            {
                // æ¸…ç† Opus è§£ç å™¨ï¼ˆå‚ç…§ FfmpegMuxReceiverï¼‰
                lock (_opusDecoderLock)
                {
                    _opusDecoder?.Dispose();
                    _opusDecoder = null;
                }
                
                lock (_opusEncoderLock)
                {
                    _stereoOpusEncoder?.Dispose();
                    _stereoOpusEncoder = null;
                }

                lock (_rtcpFeedbackLock)
                {
                    foreach (var subscription in _rtcpFeedbackSubscriptions)
                    {
                        try
                        {
                            subscription.@event.RemoveEventHandler(subscription.target, subscription.handler);
                        }
                        catch (Exception ex)
                        {
                            _logger.LogDebug(ex, "âš ï¸ ç§»é™¤ RTCP åé¦ˆäº‹ä»¶å¤„ç†ç¨‹åºå¤±è´¥: {Event}", subscription.@event.Name);
                        }
                    }

                    _rtcpFeedbackSubscriptions.Clear();
                    _rtcpSubscribedEventKeys.Clear();
                }
                
                // âœ… åœæ­¢ä¿æ´»æœºåˆ¶å¹¶æ¸…ç† DataChannel
                StopKeepalive();
                
                lock (_dataChannelLock)
                {
                    try
                    {
                        _keepaliveDataChannel?.close();
                        _keepaliveDataChannel = null;
                    }
                    catch { }
                }
                
                // âœ… æ¸…ç†æ–°çš„æ¨¡å—åŒ–è§†é¢‘å¤„ç†ç®¡é“
                if (_videoPipeline != null)
                {
                    try
                    {
                        _videoPipeline.Dispose();
                        _videoPipeline = null;
                        _logger.LogDebug("âœ… è§†é¢‘å¤„ç†ç®¡é“å·²é‡Šæ”¾");
                    }
                    catch (Exception ex)
                    {
                        _logger.LogWarning(ex, "âš ï¸ é‡Šæ”¾è§†é¢‘å¤„ç†ç®¡é“æ—¶å‘ç”Ÿå¼‚å¸¸");
                    }
                }
                
                // âœ… ä½¿ç”¨è¶…æ—¶æœºåˆ¶é‡Šæ”¾ WebRTC è¿æ¥ï¼Œé¿å…é˜»å¡å¤ªä¹…
                if (_peerConnection != null)
                {
                    try
                    {
                        var disposeTask = Task.Run(() =>
                        {
                            _peerConnection.close();
                            _peerConnection.Dispose();
                        });
                        var timeoutTask = Task.Delay(1000); // æœ€å¤šç­‰å¾… 1 ç§’
                        var completedTask = Task.WhenAny(disposeTask, timeoutTask).GetAwaiter().GetResult();
                        
                        if (completedTask == timeoutTask)
                        {
                            _logger.LogWarning("âš ï¸ WebRTC è¿æ¥é‡Šæ”¾è¶…æ—¶ï¼ˆ1ç§’ï¼‰ï¼Œå¼ºåˆ¶ç»§ç»­");
                        }
                        else
                        {
                            _logger.LogDebug("âœ… WebRTC è¿æ¥å·²é‡Šæ”¾");
                        }
                    }
                    catch (Exception ex)
                    {
                        _logger.LogWarning(ex, "âš ï¸ é‡Šæ”¾ WebRTC è¿æ¥æ—¶å‘ç”Ÿå¼‚å¸¸");
                    }
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "âŒ é‡Šæ”¾ WebRTC è¿æ¥å¤±è´¥");
            }
        }
    }
    
    /// <summary>
    /// ç®€å•çš„è§†é¢‘ç¼–ç å™¨ç«¯ç‚¹ï¼ˆå ä½ï¼‰
    /// </summary>
    internal class VideoEncoderEndpoint
    {
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šå¤„ç†è§†é¢‘ç¼–ç 
        // å¯¹äº PlayStation Remote Playï¼Œè§†é¢‘å·²ç»æ˜¯ H.264 ç¼–ç ï¼Œå¯ä»¥ç›´æ¥ä¼ è¾“
    }
    
    /// <summary>
    /// ç®€å•çš„éŸ³é¢‘ç¼–ç å™¨ç«¯ç‚¹ï¼ˆå ä½ï¼‰
    /// </summary>
    internal class AudioEncoderEndpoint
    {
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šå¤„ç†éŸ³é¢‘ç¼–ç 
        // å¯èƒ½éœ€è¦å°† AAC è½¬æ¢ä¸º OPUS
    }
}

